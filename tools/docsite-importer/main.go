package main

import (
	"bytes"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"net/http"
	"net/url"
	"os"
	"strings"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
)

type ImportResult struct {
	URL     string `json:"url"`
	Success bool   `json:"success"`
	Message string `json:"message,omitempty"`
	KnID    string `json:"knowledge_id,omitempty"`
}

type Config struct {
	APIURL      string
	Token       string
	KBBaseURL  string
	MaxPages    int
	Concurrent  int
	OutputFile  string
	URLFile     string
	ResumeFile  string
}

type Importer struct {
	config       *Config
	client       *http.Client
	visited      map[string]bool
	mu           sync.Mutex
	results      []ImportResult
	successCount int
	failCount    int
	skipCount    int
}

func NewImporter(cfg *Config) *Importer {
	return &Importer{
		config:  cfg,
		client:  &http.Client{Timeout: 60 * time.Second},
		visited: make(map[string]bool),
		results: make([]ImportResult, 0),
	}
}

func (imp *Importer) crawlURLs(baseURL string) ([]string, error) {
	fmt.Printf("ğŸ•·ï¸  å¼€å§‹çˆ¬å–æ–‡æ¡£ç«™: %s\n", baseURL)
	
	urls := []string{}
	toVisit := []string{baseURL}
	
	parsedBase, err := url.Parse(baseURL)
	if err != nil {
		return nil, fmt.Errorf("invalid base URL: %w", err)
	}
	
	for len(toVisit) > 0 && len(urls) < imp.config.MaxPages {
		current := toVisit[0]
		toVisit = toVisit[1:]
		
		imp.mu.Lock()
		if imp.visited[current] {
			imp.mu.Unlock()
			continue
		}
		imp.visited[current] = true
		imp.mu.Unlock()
		
		fmt.Printf("   å‘ç°: %s\n", current)
		urls = append(urls, current)
		
		resp, err := imp.client.Get(current)
		if err != nil {
			fmt.Printf("   âš ï¸  æ— æ³•è®¿é—® %s: %v\n", current, err)
			continue
		}
		
		if resp.StatusCode != 200 {
			resp.Body.Close()
			continue
		}
		
		doc, err := goquery.NewDocumentFromReader(resp.Body)
		resp.Body.Close()
		
		if err != nil {
			continue
		}
		
		doc.Find("a[href]").Each(func(i int, s *goquery.Selection) {
			href, exists := s.Attr("href")
			if !exists {
				return
			}
			
			linkURL, err := url.Parse(href)
			if err != nil {
				return
			}
			
			absoluteURL := parsedBase.ResolveReference(linkURL)
			
			if absoluteURL.Host != parsedBase.Host {
				return
			}
			
			absoluteURL.Fragment = ""
			urlStr := absoluteURL.String()
			
			imp.mu.Lock()
			if !imp.visited[urlStr] && len(urls)+len(toVisit) < imp.config.MaxPages {
				toVisit = append(toVisit, urlStr)
			}
			imp.mu.Unlock()
		})
		
		time.Sleep(100 * time.Millisecond)
	}
	
	fmt.Printf("âœ… çˆ¬å–å®Œæˆï¼Œå…±å‘ç° %d ä¸ªé¡µé¢\n\n", len(urls))
	return urls, nil
}

func (imp *Importer) loadURLsFromFile(filename string) ([]string, error) {
	data, err := os.ReadFile(filename)
	if err != nil {
		return nil, err
	}
	
	lines := strings.Split(string(data), "\n")
	urls := make([]string, 0, len(lines))
	
	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line != "" && !strings.HasPrefix(line, "#") {
			urls = append(urls, line)
		}
	}
	
	return urls, nil
}

func (imp *Importer) loadResumeFile(filename string) error {
	data, err := os.ReadFile(filename)
	if err != nil {
		if os.IsNotExist(err) {
			return nil
		}
		return err
	}
	
	var results []ImportResult
	if err := json.Unmarshal(data, &results); err != nil {
		return err
	}
	
	imp.mu.Lock()
	for _, r := range results {
		if r.Success {
			imp.visited[r.URL] = true
			imp.successCount++
		}
	}
	imp.results = results
	imp.mu.Unlock()
	
	fmt.Printf("ğŸ“ ä»æ–­ç‚¹æ–‡ä»¶æ¢å¤ï¼Œå·²å¯¼å…¥ %d ä¸ªé¡µé¢\n\n", imp.successCount)
	return nil
}

func (imp *Importer) saveProgress() error {
	data, err := json.MarshalIndent(imp.results, "", "  ")
	if err != nil {
		return err
	}
	
	return os.WriteFile(imp.config.ResumeFile, data, 0644)
}

func (imp *Importer) importURL(urlStr string) ImportResult {
	imp.mu.Lock()
	if imp.visited[urlStr] {
		imp.skipCount++
		imp.mu.Unlock()
		return ImportResult{URL: urlStr, Success: true, Message: "å·²å¯¼å…¥(è·³è¿‡)"}
	}
	imp.mu.Unlock()
	
	reqBody := map[string]interface{}{
		"url": urlStr,
	}
	
	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return ImportResult{URL: urlStr, Success: false, Message: fmt.Sprintf("JSONç¼–ç å¤±è´¥: %v", err)}
	}
	
	apiURL := fmt.Sprintf("%s/api/v1/knowledge-bases/%s/knowledge/url", imp.config.APIURL, imp.config.KBBaseURL)
	req, err := http.NewRequest("POST", apiURL, bytes.NewBuffer(jsonData))
	if err != nil {
		return ImportResult{URL: urlStr, Success: false, Message: fmt.Sprintf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err)}
	}
	
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("x-api-key", imp.config.Token)
	
	resp, err := imp.client.Do(req)
	if err != nil {
		return ImportResult{URL: urlStr, Success: false, Message: fmt.Sprintf("è¯·æ±‚å¤±è´¥: %v", err)}
	}
	defer resp.Body.Close()
	
	body, _ := io.ReadAll(resp.Body)
	
	if resp.StatusCode == http.StatusCreated || resp.StatusCode == http.StatusOK {
		var apiResp struct {
			Success bool `json:"success"`
			Data    struct {
				ID string `json:"id"`
			} `json:"data"`
		}
		
		if err := json.Unmarshal(body, &apiResp); err == nil && apiResp.Success {
			imp.mu.Lock()
			imp.visited[urlStr] = true
			imp.successCount++
			imp.mu.Unlock()
			
			return ImportResult{URL: urlStr, Success: true, KnID: apiResp.Data.ID}
		}
	}
	
	if resp.StatusCode == http.StatusConflict {
		var apiResp struct {
			Code string `json:"code"`
		}
		if err := json.Unmarshal(body, &apiResp); err == nil && apiResp.Code == "duplicate_url" {
			imp.mu.Lock()
			imp.visited[urlStr] = true
			imp.skipCount++
			imp.mu.Unlock()
			
			return ImportResult{URL: urlStr, Success: true, Message: "URLå·²å­˜åœ¨"}
		}
	}
	
	imp.mu.Lock()
	imp.failCount++
	imp.mu.Unlock()
	
	return ImportResult{URL: urlStr, Success: false, Message: fmt.Sprintf("HTTP %d: %s", resp.StatusCode, string(body))}
}

func (imp *Importer) importURLsConcurrently(urls []string) {
	fmt.Printf("ğŸ“¥ å¼€å§‹å¯¼å…¥ï¼Œå…± %d ä¸ªé¡µé¢ï¼Œå¹¶å‘æ•°: %d\n\n", len(urls), imp.config.Concurrent)
	
	sem := make(chan struct{}, imp.config.Concurrent)
	var wg sync.WaitGroup
	
	for i, urlStr := range urls {
		wg.Add(1)
		sem <- struct{}{}
		
		go func(index int, url string) {
			defer wg.Done()
			defer func() { <-sem }()
			
			result := imp.importURL(url)
			
			imp.mu.Lock()
			imp.results = append(imp.results, result)
			imp.mu.Unlock()
			
			status := "âœ…"
			if !result.Success {
				status = "âŒ"
			} else if result.Message != "" {
				status = "â­ï¸ "
			}
			
			msg := ""
			if result.Message != "" {
				msg = fmt.Sprintf(" - %s", result.Message)
			}
			
			fmt.Printf("[%d/%d] %s %s%s\n", index+1, len(urls), status, url, msg)
			
			if (index+1)%10 == 0 {
				if err := imp.saveProgress(); err != nil {
					fmt.Printf("âš ï¸  ä¿å­˜è¿›åº¦å¤±è´¥: %v\n", err)
				}
			}
		}(i, urlStr)
	}
	
	wg.Wait()
	
	imp.saveProgress()
}

func (imp *Importer) printSummary() {
	fmt.Printf("\n")
	fmt.Printf("========================================\n")
	fmt.Printf("ğŸ“Š å¯¼å…¥ç»Ÿè®¡\n")
	fmt.Printf("========================================\n")
	fmt.Printf("æ€»è®¡: %d\n", len(imp.results))
	fmt.Printf("âœ… æˆåŠŸ: %d\n", imp.successCount)
	fmt.Printf("â­ï¸  è·³è¿‡: %d\n", imp.skipCount)
	fmt.Printf("âŒ å¤±è´¥: %d\n", imp.failCount)
	fmt.Printf("========================================\n")
	
	if imp.failCount > 0 {
		fmt.Printf("\nå¤±è´¥çš„URL:\n")
		for _, r := range imp.results {
			if !r.Success {
				fmt.Printf("  - %s: %s\n", r.URL, r.Message)
			}
		}
	}
	
	if imp.config.OutputFile != "" {
		data, _ := json.MarshalIndent(imp.results, "", "  ")
		os.WriteFile(imp.config.OutputFile, data, 0644)
		fmt.Printf("\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: %s\n", imp.config.OutputFile)
	}
}

func main() {
	cfg := &Config{}
	
	flag.StringVar(&cfg.APIURL, "api-url", "http://localhost:8080", "WeKnora API åœ°å€")
	flag.StringVar(&cfg.Token, "token", "", "API Token (x-api-key)")
	flag.StringVar(&cfg.KBBaseURL, "kb-id", "", "çŸ¥è¯†åº“ ID")
	flag.StringVar(&cfg.URLFile, "url-file", "", "URL åˆ—è¡¨æ–‡ä»¶è·¯å¾„")
	flag.StringVar(&cfg.ResumeFile, "resume-file", "import_progress.json", "æ–­ç‚¹ç»­ä¼ æ–‡ä»¶")
	flag.StringVar(&cfg.OutputFile, "output", "import_results.json", "ç»“æœè¾“å‡ºæ–‡ä»¶")
	flag.IntVar(&cfg.MaxPages, "max-pages", 200, "æœ€å¤§çˆ¬å–é¡µé¢æ•°")
	flag.IntVar(&cfg.Concurrent, "concurrent", 3, "å¹¶å‘å¯¼å…¥æ•°")
	
	baseURL := flag.String("base-url", "", "æ–‡æ¡£ç«™åŸºç¡€ URL (è‡ªåŠ¨çˆ¬å–)")
	
	flag.Parse()
	
	if cfg.Token == "" {
		fmt.Println("âŒ é”™è¯¯: å¿…é¡»æä¾› -token")
		flag.Usage()
		os.Exit(1)
	}
	
	if cfg.KBBaseURL == "" {
		fmt.Println("âŒ é”™è¯¯: å¿…é¡»æä¾› -kb-id")
		flag.Usage()
		os.Exit(1)
	}
	
	if *baseURL == "" && cfg.URLFile == "" {
		fmt.Println("âŒ é”™è¯¯: å¿…é¡»æä¾› -base-url æˆ– -url-file")
		flag.Usage()
		os.Exit(1)
	}
	
	imp := NewImporter(cfg)
	
	if cfg.ResumeFile != "" {
		if err := imp.loadResumeFile(cfg.ResumeFile); err != nil {
			fmt.Printf("âš ï¸  æ— æ³•åŠ è½½æ–­ç‚¹æ–‡ä»¶: %v\n", err)
		}
	}
	
	var urls []string
	var err error
	
	if cfg.URLFile != "" {
		urls, err = imp.loadURLsFromFile(cfg.URLFile)
		if err != nil {
			fmt.Printf("âŒ è¯»å– URL æ–‡ä»¶å¤±è´¥: %v\n", err)
			os.Exit(1)
		}
		fmt.Printf("ğŸ“ ä»æ–‡ä»¶åŠ è½½äº† %d ä¸ª URL\n\n", len(urls))
	} else {
		urls, err = imp.crawlURLs(*baseURL)
		if err != nil {
			fmt.Printf("âŒ çˆ¬å–å¤±è´¥: %v\n", err)
			os.Exit(1)
		}
	}
	
	if len(urls) == 0 {
		fmt.Println("âš ï¸  æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¯¼å…¥çš„ URL")
		os.Exit(0)
	}
	
	imp.importURLsConcurrently(urls)
	imp.printSummary()
}
